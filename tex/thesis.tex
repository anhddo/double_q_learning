\documentclass[oneside]{book}
\usepackage{ragged2e }
\usepackage{amsfonts}
\usepackage[]{graphicx}
\usepackage[]{amsmath} 
\usepackage{import}
\usepackage{xifthen}
\usepackage{pdfpages}
\usepackage{transparent}
\usepackage{geometry}
\usepackage{mathptmx}
%\changefontsizes{13pt}
\usepackage[]{hyperref}
\usepackage[ruled,vlined, linesnumbered]{algorithm2e}
\usepackage[fontsize=13pt]{scrextend}
\geometry{
a4paper,
left=35mm,
right=20mm,
top=35mm,
bottom=30mm
}
%\usepackage[nonatbib]{neurips_2020}
\usepackage[backend=biber, style=apa]{biblatex}
%\usepackage{caption}
%\usepackage{subcaption}
\addbibresource{refs.bib}
%\renewcommand{\familydefault}{\sfdefault}

%\newcommand{\incfig}[2]{%
%    \def\svgwidth{#1\columnwidth}
%    \import{./img/}{#2.pdf_tex}
%}
\newcommand{\mbP}{\mathbb{P}}
\newcommand{\mbV}{\mathbb{V}}
\newcommand{\mbE}{\mathbb{E}}
\newcommand{\mcF}{\mathcal{F}}
\DeclareMathOperator*{\argmax}{argmax} 
\DeclareMathOperator*{\argmin}{argmin} 
\DeclareMathOperator*{\clim}{{C--lim}} 
\renewcommand{\algorithmautorefname}{Algorithm}


\author{%
  Anh Do \\
  \texttt{anhddo93@gmail.com} \\
}
\date{}
\title{Thesis: Regret bound for optimistic value iteration in average Reward MDPs}
\begin{document}
\maketitle
\tableofcontents
\justify
\printbibliography
\chapter{Acknowledgement}
I can't finish this work without the help of my family, especially mom who has 
supported me and encourage me to continue my education. I especially thank to my friend
at John Von Neumann Institute, Quan and Hieu, who has support and provide valuable information
on writing a good thesis. Moreover, I want to thank friend at VinAI research who have studied and done research
with me. And of course, I want to thank my mentor, Yasin Abbasi-Yadkori, who has guided me and 
taught me on reinforcement learning. Without the help of friend and family, I won't be able to finish this thesis
\chapter{Introduction}
\chapter{Related work}
\chapter{Our work}

\begin{algorithm}[H]
\SetAlgoLined
  \textbf{Input} : Scale parameter H, regularization parameter  $\lambda$, 
  confidence level  $\delta  \in (0,1) $, the number of phase T.\\
 \textbf{Initialization}: Let $\gamma=1-1 / H, \tilde{V}_{1}=H, \widetilde{Q}_{1}=H$ \\
 \For{t= 1 \dots , T}{
Calculate the empirical covariance matrix:  $M_{t}=\sum_{k=1}^{t-1} \phi\left(s_{k}, a_{k}\right) \phi\left(s_{k}, a_{k}\right)^{\top}+\lambda I$ \\
Update the regularized least square estimate as:
  \[
    w_{t}=M_{t}^{-1} \sum_{k=1}^{t-1} \phi\left(s_{k}, a_{k}\right)\left[r\left(s_{k}, a_{k}\right)+\gamma \widetilde{V}_{t-1}\left(s_{k+1}\right)\right] 
  \] \\
Find the optimistic estimation of Q-function: $\widetilde{Q}_{t}(s, a)=\phi(s, a)^{\top} w_{t}+\beta_{t}(\delta)\|\phi(s, a)\|_{M_{t}^{-1}}$ \\
  Take action: $a_{t}=\operatorname{argmax}_{a} \widetilde{Q}_{t}\left(s_{t}, a\right)$ and observe $s _{t+1}$ 
  }
 
 \caption{Optimistic value iteration for average reward problems (OVI)}
\end{algorithm}
We start with the following regret decomposition:
\begin{equation} 
\begin{aligned}
\operatorname{Regret}_{T} &=\sum_{t=1}^{T}\left(\lambda_{*}-r\left(s_{t}, a_{t}\right)\right) \\
&=\sum_{t=1}^{T}\left(\lambda_{*}-(1-\gamma) \tilde{V}_{*}\left(s_{t}\right)\right)+\sum_{t=1}^{T}\left(\tilde{V}_{*}\left(s_{t}\right)-\widetilde{Q}_{*}\left(s_{t}, a_{t}\right)\right) \\
  & +\sum_{t=1}^{T}\left(\widetilde{Q}_{*}\left(s_{t}, a_{t}\right)-\gamma \tilde{V}_{*}\left(s_{t}\right)-r\left(s_{t}, a_{t}\right)\right) \\
& \leq(1-\gamma) \operatorname{span}\left(V_{*}\right) T+\sum_{t=1}^{T}\left(\tilde{V}_{*}\left(s_{t}\right)-\widetilde{Q}_{*}\left(s_{t}, a_{t}\right)\right) \\
  &+2 \operatorname{span}\left(V_{*}\right) \sqrt{2 T \log (1 / \delta)}+2 \operatorname{span}\left(V_{*}\right)
\end{aligned}
\end{equation}

It can be verified that:
\[
  w_{\pi}=M_{t}^{-1} \sum_{k=1}^{t-1} \phi_{k}\left(r_{k}+\gamma P_{k} \widetilde{V}_{\pi}\right)+\lambda M_{t}^{-1}\left(\theta+\gamma \mu \widetilde{V}_{\pi}\right) 
\]

The parameter estimate of the algorithm at time t is:
\[
  w_{t}=M_{t}^{-1} \sum_{k=1}^{t-1} \phi_{k}\left(r_{k}+\gamma \tilde{V}_{t-1}\left(s_{k+1}\right)\right) 
\]

We have that:
\begin{equation} 
\begin{aligned}
w_{t}-w_{\pi} &=\gamma M_{t}^{-1} \sum_{k=1}^{t-1} \phi_{k}\left(\tilde{V}_{t-1}\left(s_{k+1}\right)-P_{k} \tilde{V}_{t-1}+P_{k}\left(\tilde{V}_{t-1}-\tilde{V}_{\pi}\right)\right)-\lambda M_{t}^{-1}\left(\theta+\gamma \mu \tilde{V}_{\pi}\right) \\
&=\gamma M_{t}^{-1} S_{t}+\gamma M_{t}^{-1} \sum_{k=1}^{t-1} \phi_{k} P_{k}\left(\tilde{V}_{t-1}-\tilde{V}_{\pi}\right)-\lambda M_{t}^{-1}\left(\theta+\gamma \mu \widetilde{V}_{\pi}\right)
\end{aligned}
\end{equation}

\chapter{Experimetal resuls}
\chapter{Conclusion}

\end{document}
